{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация названий групп\n",
    "\n",
    "Данные\n",
    "\n",
    "1. Датасет с именами групп\n",
    "2. Фильтруем те, что хотя бы начинаются с ascii символов, чтобы не попадал бред (там мало другого, ничего все равно не выйдет)\n",
    "3. Данные нужны только как обучение нграмм, поэтому по сути это строчки, нам не важно их делить по группам, просто перемешать, тогда переносы строк мы сделаем eos и потом учтем при генерации\n",
    "4. Для удобства возьмем только латиницу, пробел и перенос строки (конец слова)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./death-metal/bands.csv')\n",
    "df[df['name']<= 'Z'][['name']].to_csv('bands.txt', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bands.txt') as f:\n",
    "    names = f.readlines()\n",
    "    random.shuffle(names)\n",
    "    names = ''.join(names)\n",
    "train = names[:int(len(names)*0.7)]\n",
    "valid = names[int(len(names)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = ' '+'\\n'+string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = tt.zeros(len(string)).long()\n",
    "    for ci in range(len(string)):\n",
    "        try:\n",
    "            tensor[ci] = all_characters.index(string[ci])\n",
    "        except:\n",
    "            pass\n",
    "    return tensor\n",
    "\n",
    "def random_training_set(chunk_len, batch_size, file):\n",
    "    limit = len(file) - chunk_len\n",
    "    inp = tt.LongTensor(batch_size, chunk_len)\n",
    "    target = tt.LongTensor(batch_size, chunk_len)\n",
    "    \n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, limit)\n",
    "        chunk = file[start_index : start_index + chunk_len + 1]\n",
    "        inp[bi] = char_tensor(chunk[:-1])\n",
    "        target[bi] = char_tensor(chunk[1:])\n",
    "    \n",
    "    return inp, target\n",
    "\n",
    "def perplexity(x):\n",
    "    return 2**x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_epoch(inp, target, model, optimizer, criterion, curr_epoch):\n",
    "\n",
    "    decoder.train()\n",
    "    hidden = decoder.init_hidden(batch_size)\n",
    "    decoder.zero_grad()\n",
    "    \n",
    "    train_loss = 0\n",
    "    perplexities = []\n",
    "    \n",
    "    for ci in range(chunk_len):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, hidden = decoder(inp[:,ci], hidden)\n",
    "        loss = criterion(output.view(batch_size, -1), target[:,ci])\n",
    "        perplexities.append(perplexity(loss.item()))\n",
    "        \n",
    "        current_loss = loss.data.cpu().detach().item()\n",
    "        loss_smoothing = ci / (ci+1)\n",
    "        train_loss = loss_smoothing * train_loss + (1 - loss_smoothing) * current_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    result_perplexity = np.mean(perplexities)\n",
    "    return train_loss, result_perplexity\n",
    "\n",
    "def _test_epoch(inp, target, model, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    loss = 0\n",
    "    perplexities = []\n",
    "    \n",
    "    hidden = decoder.init_hidden(batch_size)\n",
    "    \n",
    "    with tt.no_grad():\n",
    "        for ci in range(chunk_len):\n",
    "            output, hidden = decoder(inp[:,ci], hidden)\n",
    "            loss = criterion(output.view(batch_size, -1), target[:,ci])\n",
    "            perplexities.append(perplexity(loss.item()))\n",
    "            epoch_loss += loss.data.item()\n",
    "    \n",
    "    result_perplexity = np.mean(perplexities)\n",
    "    return epoch_loss / chunk_len, result_perplexity\n",
    "\n",
    "\n",
    "def nn_train(model, train, valid, criterion, optimizer, n_epochs=100, scheduler=None, early_stopping=0):\n",
    "    \n",
    "    print('EPOCH\\tValid Loss\\t Train Loss\\tV.Perplexity\\tT.Perplexity')\n",
    "    \n",
    "    best_epoch = None\n",
    "    prev_loss = 100500\n",
    "    es_epochs = 0\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        try:\n",
    "            train_loss, train_per = _train_epoch(*random_training_set(chunk_len, \n",
    "                                                                      batch_size, \n",
    "                                                                      train),\n",
    "                                                 model, optimizer, criterion, epoch)\n",
    "            valid_loss, valid_per = _test_epoch(*random_training_set(chunk_len, \n",
    "                                                                     batch_size, \n",
    "                                                                     valid),\n",
    "                                                model, criterion)\n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "            \n",
    "            if epoch % 100 == 0 or epoch == n_epochs-1:\n",
    "                print('%s \\t %.5f \\t %.5f \\t %.5f \\t %.5f' % (str(epoch),\n",
    "                                                                 valid_loss,\n",
    "                                                                 train_loss,\n",
    "                                                                 valid_per,\n",
    "                                                                 train_per))\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        \n",
    "        if early_stopping > 0:\n",
    "            if valid_loss > prev_loss:\n",
    "                es_epochs += 1\n",
    "            else:\n",
    "                es_epochs = 0\n",
    "            if es_epochs >= early_stopping:\n",
    "                break\n",
    "            prev_loss = min(prev_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        super(MyModel, self).__init__()\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, 1)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        \n",
    "        embed = self.encoder(input)\n",
    "        output, hidden = self.rnn(embed.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return tt.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "chunk_len = 256 # побольше\n",
    "\n",
    "decoder = MyModel(input_size=len(all_characters),\n",
    "                  hidden_size=hidden_size, \n",
    "                  output_size=len(all_characters))\n",
    "\n",
    "optimizer = tt.optim.Adam(decoder.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH\tValid Loss\t Train Loss\tV.Perplexity\tT.Perplexity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdea75d168244548aa7a5658e044278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 3.87222 \t 4.02740 \t 14.65978 \t 16.30981\n",
      "100 \t 2.76785 \t 2.76734 \t 6.92133 \t 6.91242\n",
      "200 \t 2.76340 \t 2.73453 \t 6.88434 \t 6.75855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dkbrz/.local/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type MyModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "nn_train(decoder, train, valid, criterion, optimizer, n_epochs=1000, early_stopping=100)\n",
    "tt.save(decoder, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(decoder, prime_str='\\n', predict_len=30, temperature=0.8):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = char_tensor(prime_str).unsqueeze(0)\n",
    "    predicted = ''\n",
    "\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p], hidden)\n",
    "        \n",
    "    inp = prime_input[:,-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = tt.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "        \n",
    "        if predicted and predicted_char == '\\n':\n",
    "            break\n",
    "        else:\n",
    "            predicted += predicted_char\n",
    "            inp = char_tensor(predicted_char).unsqueeze(0)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbryiad\n",
      "Sawncre\n",
      "Mulphaw Inster Ins\n",
      "Intesionar Kargons\n",
      "Abrgge Pred Cargomtenc\n",
      "ISchenc Cad\n",
      "Kiclerepte\n",
      "Eredonst\n",
      "Grormerbutardar\n",
      "Edombadong\n",
      "Svadaumne\n",
      "Mated\n",
      "Dead\n",
      "Varwace\n",
      "Elvear\n",
      "Mornphare\n",
      "Paromeredenca\n",
      "Premist\n",
      "If Vheadarw\n",
      "ERadeadong Embre\n",
      "Gerns Caind tore\n",
      "Lesorta us Cemnc\n",
      "Gredemstamum\n",
      "Sompeca\n",
      "GM Insticcar Catha\n",
      "Inctredarcwomiad\n",
      "AKilarge\n",
      "Rorosister\n",
      "Efmpspmsaderbaaring Diad  Bere\n",
      "Sa Crpitcarara\n",
      "Diarg Bets\n",
      "Propsy Ertatar\n",
      "Ivicely a Kessitler\n",
      "Edtar\n",
      "Eng H\n",
      "Portaatare\n",
      "Iploncer\n",
      "IHestarbon\n",
      "Saruphicage\n",
      "Chatorwuariaw Diad\n",
      "Aong Verist\n",
      "LIdmbonic\n",
      "Cumudt\n",
      "Comn\n",
      "Oviargemer\n",
      "Graapter\n",
      "Echado of Vit\n",
      "Everncy\n",
      "Empshadora\n",
      "Gortal Baw\n",
      "Prophiarbad Bicang Bupige\n",
      "IGprpads\n",
      "Imbombs\n",
      "Mil Had\n",
      "IKOprtatatar\n",
      "Paermad Wher \n",
      "Gred DScyne\n",
      "Sponfonc\n",
      "Dear\n",
      "Margomeron\n",
      "Incadynem\n",
      "Groceremarcad Vermsmn\n",
      "Ipncrememonon\n",
      "Graw\n",
      "jmfemonst Dres Cromars\n",
      "Etaroo\n",
      "Phitariaondart\n",
      "Demoran\n",
      "IL Diads\n",
      "Gartrol\n",
      "Furppets\n",
      "SInfett Darnon\n",
      "Pariatar Cawne\n",
      "Sarewn\n",
      "Burepsl\n",
      "Murggemt Crsptormen\n",
      "Igrapon\n",
      "Ededernads\n",
      "Gurone\n",
      "Sadph Ins Bade\n",
      "IqYamont Epembaton\n",
      "IIHmphare\n",
      "Goritembares\n",
      "Ovacern\n",
      "Qidoncone\n",
      "Grad\n",
      "Sucurmas Bingh\n",
      "Giharnd\n",
      "Parwromedadpon\n",
      "Sadong Bre Essy Darng\n",
      "Qr yf Cons Dead\n",
      "Spherbarwron\n",
      "Vitargerr\n",
      "Iqorax\n",
      "Sadon\n",
      "Instormamb\n",
      "Sucaaded\n",
      "Edpharophe\n",
      "Comicedudaat\n",
      "Harow Penction\n"
     ]
    }
   ],
   "source": [
    "for x in range(100):\n",
    "    print(generate(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
