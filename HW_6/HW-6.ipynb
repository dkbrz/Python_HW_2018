{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что попробовал:**\n",
    "1. поменять размер вектора (100, 200, 300) - на 300 было лучше - другие модели не подходили по памяти\n",
    "2. Использовать разницу среднего по векторам (типа разница между оригинальным постом и комментариями) - сильно хуже, чем просто комментарий\n",
    "3. использовать склеенные тексты - вроде чуть лучше, но чуть-чуть\n",
    "4. поменять токенайзер, чтобы вернуть знаки препинания (только это побило бейзлайн)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d19e5a3caa6ff123e91a2e1ba62194087469aec4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, LabelField, BucketIterator, ReversibleField, TabularDataset\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "af0e270a19b42c39cdf68cfb4cb387dfc0e2f333"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_en.remove_pipe('tagger')\n",
    "spacy_en.remove_pipe('ner')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.lemma_ for tok in spacy_en.tokenizer(text)] #if tok.text.isalpha()]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "27eec76b2f1513330714792dd2c9bec99769dde1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = tt.device('cuda:0' if tt.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3b9213a10488f00699de9ddb1106798926815f22"
   },
   "outputs": [],
   "source": [
    "#classes={\n",
    "#    0:0,\n",
    "#    '1':1\n",
    "#}\n",
    "\n",
    "TEXT = Field(include_lengths=True, batch_first=True, \n",
    "             tokenize=tokenizer,\n",
    "             eos_token='<eos>',\n",
    "             lower=True,\n",
    "             stop_words=nltk.corpus.stopwords.words('english')\n",
    "            )\n",
    "LABEL = LabelField(dtype=tt.int64)\n",
    "\n",
    "dataset = TabularDataset('../input/train-balanced-sarcasm.csv', format='csv', \n",
    "                         fields=[('label', LABEL), ('text', TEXT),\n",
    "                                 (None, None),(None, None),(None, None),(None, None),\n",
    "                                 (None, None),(None, None),(None, None),\n",
    "                                 ('parental', TEXT)], \n",
    "                                 #(None, None)], \n",
    "                         skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "fd2c69292485d0740d1c2e34453059578d1ad203"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [03:42, 3.88MB/s]                           \n",
      "100%|█████████▉| 399506/400000 [00:50<00:00, 8093.24it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68344"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(dataset, min_freq=5, vectors=\"glove.6B.300d\")\n",
    "#TEXT.build_vocab(dataset, min_freq=5)\n",
    "len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1d1fd087a1f9280fb7ce12ddd897df64b9217044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "71b0d080ee789df8d318c6f269c5572b08279a88"
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "03afdfaebbe7c2310eb417cbb19f71dcffd0e3ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "011528a2dd88b8d4a44271713d20e620e492ea12"
   },
   "outputs": [],
   "source": [
    "train, test = dataset.split(0.8, stratified=True)\n",
    "train, valid = train.split(0.9, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "fbababd1dd904428ca30eb83ada24dd06e39f2eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399506/400000 [01:10<00:00, 8093.24it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['0', '1'], dtype='<U1'), array([363897, 363897]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x.label for x in train.examples], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "5143cf1bbb4e6e3089b62faa60c5d1c79bee37e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1'], dtype='<U1'), array([40433, 40433]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x.label for x in valid.examples], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "9198182f841dc9fe7b3f1356aa93c37649235e44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1'], dtype='<U1'), array([101083, 101083]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x.label for x in test.examples], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "dc32e79eb99c34df40c4cf35a51f60f00be08181"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, weights_matrix):\n",
    "        super(MyModel, self).__init__()\n",
    "        #self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.embedding = nn.Embedding.from_pretrained(weights_matrix)\n",
    "        self.embedding.requires_grad = False\n",
    "        self.device = device\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=embed_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                          )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * 2 *2, 2)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        #batch = batch.to(self.device)\n",
    "        x, x_lengths = batch.text\n",
    "        x = x.to(self.device)\n",
    "        x = self.embedding(x)\n",
    "        #y, y_lengths = batch.parental\n",
    "        #y = y.to(self.device)\n",
    "        #y = self.embedding(y)\n",
    "        #s = [y.shape[0], 1, y.shape[1]]\n",
    "        #y = y.resize_(*s)\n",
    "        #s = [x.shape[0], 1, x.shape[1]]\n",
    "        #x = x.resize_(*s)\n",
    "        #print (x.shape, y.shape)\n",
    "        #x = tt.cat([x,y], dim=1)\n",
    "        #print (x.shape, x)\n",
    "        #if x_lengths is not None:\n",
    "        #    x_lengths = x_lengths.view(-1).tolist()\n",
    "        #    x = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "        batch.label = batch.label.to(self.device)\n",
    "            \n",
    "        _, (hidden, cell) = self.rnn(x)\n",
    "        x = x.detach()\n",
    "        hidden = hidden.transpose(0,1)\n",
    "        cell = cell.transpose(0,1)\n",
    "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
    "        cell = cell.contiguous().view(cell.size(0),-1)\n",
    "        x = tt.cat([hidden, cell], dim=1).squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b3e02c23bc2a1813173227e0fe1d099a039ee1b3"
   },
   "outputs": [],
   "source": [
    "tt.cuda.empty_cache()\n",
    "#tt.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "batch_size = 32\n",
    "\n",
    "model = MyModel(len(TEXT.vocab.itos),\n",
    "                embed_size=300,\n",
    "                hidden_size=128,\n",
    "                weights_matrix = TEXT.vocab.vectors\n",
    "               )\n",
    "#device = tt.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_sizes=(batch_size, batch_size, 100),\n",
    "    shuffle=True,\n",
    "    sort_key=lambda x: len(x.text)+len(x.parental),\n",
    "    sort_within_batch=True,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True, cooldown=5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "06f212c7aa1c7ff5a322fc23efd8ac18c4717295"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def count_accuracy(model, iterator):\n",
    "    model.eval()\n",
    "    acc_sum = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    with tt.no_grad():\n",
    "        for batch in tqdm_notebook(iterator, leave=False):\n",
    "            #pred = model(batch)\n",
    "            A = tt.nn.functional.softmax(model(batch), dim=1).cpu().numpy().argmax(axis=1)\n",
    "            B = batch.label.cpu()\n",
    "            acc = accuracy_score(A, B)\n",
    "            acc_sum += acc\n",
    "\n",
    "    return acc_sum / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "51de31415a83a2b3dd5ab58974ae13aa53bc5236"
   },
   "outputs": [],
   "source": [
    "def _train_epoch(model, iterator, optimizer, criterion, curr_epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch.label.detach())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss = loss.data.cpu().detach().item()\n",
    "        \n",
    "        loss_smoothing = i / (i+1)\n",
    "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
    "\n",
    "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
    "\n",
    "    return running_loss\n",
    "\n",
    "def _test_epoch(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    with tt.no_grad():\n",
    "        for batch in iterator:\n",
    "            pred = model(batch)\n",
    "            loss = criterion(pred, batch.label)\n",
    "            epoch_loss += loss.data.item()\n",
    "\n",
    "    return epoch_loss / n_batches\n",
    "\n",
    "\n",
    "def nn_train(model, train_iterator, valid_iterator, criterion, optimizer, n_epochs=100,\n",
    "          scheduler=None, early_stopping=0, test_iterator=None):\n",
    "\n",
    "    prev_loss = 100500\n",
    "    es_epochs = 0\n",
    "    best_epoch = None\n",
    "    history = pd.DataFrame()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = _train_epoch(model, train_iterator, optimizer, criterion, epoch)\n",
    "        valid_loss = _test_epoch(model, valid_iterator, criterion)\n",
    "\n",
    "        valid_loss = valid_loss\n",
    "        print('validation loss %.5f' % valid_loss)\n",
    "\n",
    "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
    "        history = history.append(record, ignore_index=True)\n",
    "\n",
    "        if early_stopping > 0:\n",
    "            if valid_loss > prev_loss:\n",
    "                es_epochs += 1\n",
    "            else:\n",
    "                es_epochs = 0\n",
    "\n",
    "            if es_epochs >= early_stopping:\n",
    "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
    "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
    "                break\n",
    "\n",
    "            prev_loss = min(prev_loss, valid_loss)\n",
    "        print (count_accuracy(model, test_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего получилось на 2 эпохах, это и есть итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "ae51c5391f38644430b13b25df93d86f661e0688",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3b07c872834dd98ca4f266198fa328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 0', max=22744, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_train(model, train_iterator, valid_iterator, criterion, optimizer, scheduler=scheduler, \n",
    "        n_epochs=2, early_stopping=6, test_iterator=test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "cff346bfc9616452ca76545c9ea939044920c597"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568ed38d2e0a4dffa92f3ce9ed62a005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2022), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7099169738932407"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_accuracy(model, test_iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
